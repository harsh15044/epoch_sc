{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66963e69-76f5-4f7e-a5a5-6275731950d6",
   "metadata": {},
   "source": [
    "### Task-2\n",
    "## K-Nearest Neighbors (KNN) Classifier - From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2954a7-486c-47e7-89d3-2f0363567f2d",
   "metadata": {},
   "source": [
    "Let's kick-off by importing modules and writing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43019368-f689-4ae5-b8e6-11ca87404e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import multimode\n",
    "\n",
    "def calculate_distance(a,b,p):\n",
    "    distance = None\n",
    "    if p==None:\n",
    "        distance = 1 - (a.T@b)/(np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    else:\n",
    "        distance = (a-b)\n",
    "        distance = np.abs(distance)\n",
    "        distance = distance**p\n",
    "        distance = np.sum(distance)\n",
    "        distance = distance**(1/p)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def find_mode(numbers):\n",
    "    #getting an array of mode(s)\n",
    "    mode = multimode(numbers)\n",
    "\n",
    "    #Return the mode\n",
    "    #return randmoly if multiple modes found\n",
    "    return np.random.choice(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e1360-df94-4a66-bb1e-afa2f57902b8",
   "metadata": {},
   "source": [
    "Here comes our implementation of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d59f98ab-f8f1-4161-97fd-afd3480d764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Classifier():\n",
    "    \"\"\"\n",
    "        A simple implementation of the KNN algorithm.\n",
    "\n",
    "        parameters:\n",
    "            k               : how many neighbours to consider for predicting the label\n",
    "            distance_metric : on what basis to find the nearest neighbors. Currently supports \"euclidean\", \"manhattan\", \"minkowski\", \"cosine\".\n",
    "            p               : p value required for minkowski distance. pass 'np.inf' for L-infinity norm\n",
    "            is_weighted     : Set to True if you want to implement weighted KNN.\n",
    "\n",
    "        Methods:\n",
    "            train_test_split() : splits the data into train and test data according to the parameter train_data (which tells what proportion of the total data to be taken for trainig). Returns 4 arrays.\n",
    "            fit()              : Stores the input data to predict label for new points\n",
    "            predict()          : predicts the label for a set of given points\n",
    "            predict_one()      : predicts the label for a single given point\n",
    "            accuracy_checker() : Compares the predicted label with the actual labels to calculate the accuracy\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,k=3, distance_metric=\"euclidean\", p=None, is_weighted=False):\n",
    "\n",
    "        #checking if invalid parameter passed for distance_metric\n",
    "        if(distance_metric not in [\"euclidean\", \"manhattan\", \"minkowski\", \"cosine\"]):\n",
    "            raise ValueError('distance_metric can only take values \"euclidean\", \"manhattan\", \"minkowski\", \"cosine\"')\n",
    "\n",
    "        #checking if valid p is supplied in case of minkowski\n",
    "        if(distance_metric == \"minkowski\" and (p==None or p<1)):\n",
    "            raise ValueError(\"The value of p should be a nunmerical value greater than or equal to 1\")\n",
    "\n",
    "        #everything's fine, let's proceed\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.is_weighted = is_weighted\n",
    "\n",
    "        #We will get the data when the fit function is called\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "        #assigning self.p\n",
    "        if(distance_metric==\"euclidean\"):\n",
    "            self.p=2\n",
    "        elif(distance_metric==\"manhattan\"):\n",
    "            self.p=1\n",
    "        elif(distance_metric==\"minkowski\"):\n",
    "            self.p=p\n",
    "        elif(distance_metric==\"cosine\"):\n",
    "            self.p=None\n",
    "\n",
    "        #done with the initialization\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "    def train_test_split(self, X, y, train_data =0.7):\n",
    "        #checking if dimensions of X and y match\n",
    "        if(len(X) != len(y)):\n",
    "            raise SizeError(f\"The size of X ({len(X)}) does not match with that of y ({len(y)})\")\n",
    "\n",
    "        #checking if valid train_data parameter passed or not\n",
    "        if(train_data<=0 or train_data >1):\n",
    "            raise ValueError(f\"Invalid value for train_data. It should belong to (0,1]\")\n",
    "\n",
    "        #shuffling the indices\n",
    "        indices = range(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test  = []\n",
    "        y_test  =[]\n",
    "\n",
    "        #taking the first train_data proportion of indoces for training and later for test\n",
    "        num_training_points = len(X)//train_data\n",
    "        for i in range(num_training_points+1):\n",
    "            X_train.append(X[i])\n",
    "            y_train.append(y[i])\n",
    "\n",
    "        for i in range(num_training_points+1, len(X)):\n",
    "            X_test.append(X[i])\n",
    "            y_test.append(y[i])\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #checking if dimensions of X and y match\n",
    "        if(len(X) != len(y)):\n",
    "            raise SizeError(f\"The size of X ({len(X)}) does not match with that of y ({len(y)})\")\n",
    "\n",
    "        #everything is fine, let's store the data\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "########################################################################\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predicted = []\n",
    "\n",
    "        for x_test in X_test:\n",
    "            #first calculating the distances\n",
    "            distances = []\n",
    "            for x_data in self.X:\n",
    "                distances.append(calculate_distance(x_test, x_data, self.p))\n",
    "\n",
    "            #now we have distances array\n",
    "            distances = np.array(distances)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_nearest_indices = sorted_indices[:self.k]\n",
    "\n",
    "            #if data point exists in X, return the same label\n",
    "            if(distances[sorted_indices[0]] == 0):\n",
    "                predicted.append(self.y[sorted_indices[0]])\n",
    "\n",
    "            #else we will predict\n",
    "            else:\n",
    "                #if weighted\n",
    "                if(self.is_weighted):\n",
    "                    freq = np.zeros(3)\n",
    "\n",
    "                    distances_sum = sum([distances[index] for index in k_nearest_indices])\n",
    "                    for index in k_nearest_indices:\n",
    "                        freq[y[index]] += 1/distances[index]\n",
    "\n",
    "                    predicted_label = np.argmax(freq)\n",
    "\n",
    "                #normal KNN\n",
    "                else:\n",
    "                    labels = [self.y[index] for index in k_nearest_indices]\n",
    "                    predicted_label = find_mode(labels)\n",
    "\n",
    "                predicted.append(predicted_label)\n",
    "\n",
    "        #We have predicted them completely, lets return them\n",
    "        return predicted\n",
    "########################################################################\n",
    "\n",
    "\n",
    "    def predict_one(self,x):\n",
    "        #first calculating the distances\n",
    "        distances = []\n",
    "        for x_data in self.X:\n",
    "            distances.append(calculate_distance(x, x_data, self.p))\n",
    "\n",
    "        #now we have distances array\n",
    "        distances = np.array(distances)\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        k_nearest_indices = sorted_indices[:self.k]\n",
    "\n",
    "        #if data point exists in X, return the same label\n",
    "        if(distances[sorted_indices[0]] == 0):\n",
    "            return (self.y[sorted_indices[0]])\n",
    "\n",
    "        #else we will predict\n",
    "        else:\n",
    "            #if weighted\n",
    "            if(self.is_weighted):\n",
    "                freq = np.zeros(3)\n",
    "    \n",
    "                distances_sum = sum([distances[index] for index in k_nearest_indices])\n",
    "                for index in k_nearest_indices:\n",
    "                    freq[y[index]] += 1/distances[index]\n",
    "    \n",
    "                return np.argmax(freq)\n",
    "    \n",
    "            #normal KNN\n",
    "            else:\n",
    "                labels = [self.y[index] for index in k_nearest_indices]\n",
    "                return find_mode(labels)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "    def accuracy_checker(self, y_predicted, y_true):\n",
    "\n",
    "        if(len(y_predicted) != len(y_true)):\n",
    "            raise SizeError(\"Size of given arrays do not match.\")\n",
    "\n",
    "\n",
    "        total = len(y_predicted)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(y_predicted)):\n",
    "            if(y_predicted[i]==y_true[i]):\n",
    "                correct+=1\n",
    "\n",
    "        return correct/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7fc1a-077b-4fa8-a5b0-c78a96e85ec8",
   "metadata": {},
   "source": [
    "Lets use this implementation, and test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9cdf1323-7732-44e0-ba24-07efd9f10ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(1), np.int64(0), np.int64(2)]\n",
      "The accuracy in this case is 100.0%.\n"
     ]
    }
   ],
   "source": [
    "### given data\n",
    "data = [\n",
    "    [150, 7.0, 1, 'Apple'],\n",
    "    [120, 6.5, 0, 'Banana'],\n",
    "    [180, 7.5, 2, 'Orange'],\n",
    "    [155, 7.2, 1, 'Apple'],\n",
    "    [110, 6.0, 0, 'Banana'],\n",
    "    [190, 7.8, 2, 'Orange'],\n",
    "    [145, 7.1, 1, 'Apple'],\n",
    "    [115, 6.3, 0, 'Banana']\n",
    "]\n",
    "\n",
    "#creating an instance of our class\n",
    "knn_classifier = KNN_Classifier(k=4, is_weighted=True)\n",
    "\n",
    "#splitting into features and labels\n",
    "X, labels = np.array([row[:-1] for row in data]), np.array([row[-1] for row in data])\n",
    "\n",
    "#encoding the y labels\n",
    "#apples = 0, Banana = 1, Orange = 2\n",
    "y=[]\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==\"Apple\"):\n",
    "        y.append(0)\n",
    "    elif(labels[i]==\"Banana\"):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(2)\n",
    "\n",
    "#fitting our model\n",
    "knn_classifier.fit(X,y)\n",
    "\n",
    "\n",
    "#test data\n",
    "test_data = np.array([\n",
    "    [118, 6.2, 0],  # Expected: Banana\n",
    "    [160, 7.3, 1],  # Expected: Apple\n",
    "    [185, 7.7, 2]   # Expected: Orange\n",
    "])\n",
    "y_test = np.array([1,0,2])\n",
    "\n",
    "X_test = np.array(test_data)\n",
    "\n",
    "y_predicted = knn_classifier.predict(X_test)\n",
    "print(y_predicted)\n",
    "\n",
    "print(f\"The accuracy in this case is {knn_classifier.accuracy_checker(y_predicted, y_test) * 100}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fccaa-1e98-4913-a516-a4188440c5fb",
   "metadata": {},
   "source": [
    "The output is Banana, Apple, Orange, which is what we expected. This implies that our implementation is working fine.\n",
    "\n",
    "On playing around with $k$ values, we realize that only values till $3$ work fine with KNN, however Weighted-KNN works fine even for higher values of $k$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
